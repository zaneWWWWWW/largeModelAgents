CUDA_VISIBLE_DEVICES=0
Mon Nov 24 16:13:55 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA RTX A6000               On  | 00000000:3B:00.0 Off |                  Off |
| 30%   42C    P8              17W / 300W |      3MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
torch: 2.5.1+cu121 cuda: True
[INFO|2025-11-24 16:14:18] llamafactory.hparams.parser:468 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.bfloat16
[INFO|2025-11-24 16:14:18] llamafactory.data.loader:143 >> Loading dataset sft_student_mental.jsonl...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 14880, 100345, 105051, 43815, 102086, 116743, 105151, 90395, 91680, 66017, 5370, 5122, 450, 4011, 8274, 7, 15, 12, 18, 701, 18056, 8274, 7, 15, 12, 18, 701, 5214, 10933, 1445, 603, 91, 27051, 292, 25880, 91, 721, 1523, 2178, 91, 55151, 763, 701, 5458, 16031, 673, 10405, 7, 15, 12, 24, 8, 8997, 872, 25, 88940, 225, 21887, 100703, 99235, 3837, 108386, 3837, 35946, 104044, 99879, 35946, 104858, 87267, 113783, 34187, 3837, 43288, 104029, 99491, 104573, 1773, 35946, 114606, 94432, 872, 25, 49434, 239, 33108, 35946, 104858, 20412, 99562, 101181, 3837, 97639, 104080, 99461, 109745, 34187, 3837, 104133, 20, 104252, 99657, 1773, 100543, 24562, 3837, 111003, 42411, 87267, 113783, 34187, 8997, 872, 25, 49434, 239, 106546, 100648, 58405, 69249, 33108, 46944, 57750, 9370, 101194, 105610, 33108, 87805, 1773, 42411, 104136, 36587, 99650, 100009, 99614, 3837, 105984, 104083, 100698, 8997, 872, 25, 49434, 239, 79478, 99601, 106822, 105919, 104432, 1773, 35946, 104014, 106118, 85336, 100111, 100648, 58405, 3837, 97639, 103977, 99519, 111553, 116784, 8997, 872, 25, 49434, 239, 109623, 35946, 107999, 101901, 111852, 42411, 3837, 70361, 100641, 102497, 1773, 110146, 104359, 104899, 103952, 104617, 33108, 101064, 8997, 872, 25, 49434, 239, 99880, 103952, 104617, 100006, 101954, 3837, 101064, 117809, 1773, 101553, 99880, 99519, 111553, 99564, 26939, 103952, 100145, 8997, 872, 25, 49434, 239, 101045, 99165, 104409, 1773, 102389, 3837, 106922, 99242, 42411, 3837, 104359, 104899, 103952, 104617, 24968, 104702, 3837, 35946, 104083, 102827, 111553, 3837, 70361, 100641, 102497, 8997, 872, 25, 18137, 224, 96, 110693, 99730, 109031, 94432, 872, 25, 4891, 98, 121, 9370, 3837, 105351, 101066, 85336, 104482, 1773, 102570, 103929, 100364, 1773, 151645, 198, 151644, 77091, 198, 4913, 450, 4011, 8274, 788, 220, 16, 11, 330, 276, 16308, 8274, 788, 220, 17, 11, 330, 80943, 10933, 788, 330, 6697, 497, 330, 12038, 16031, 673, 10405, 788, 220, 21, 92, 151645, 198]
inputs:
<|im_start|>system
You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>
<|im_start|>user
请根据对话内容评估四项标签，并只输出JSON：depression_level(0-3), anxiety_level(0-3), risk_flag(none|suicidal|self_harm|violence), student_distress_score(0-9)。
user: 心理咨询师，你好，我最近发现我老公可能出轨了，这让我非常痛苦。我该怎么办？
user: 我和我老公是大学同学，我们在一起已经十几年了，有一个5岁的孩子。半年前，我发现他可能出轨了。
user: 我发现了他的手机里和一个女的有很多短信和电话。他解释说他们只是朋友，但我很难相信。
user: 我们现在相处得很紧张。我总是忍不住去查看他的手机，我们也会因为这件事情争吵。
user: 我想知道我该如何才能原谅他，重新建立信任。我真的不想失去我们的婚姻和家庭。
user: 我希望我们的婚姻能够幸福，家庭和睦。我不希望因为这件事情影响到我们的关系。
user: 我其实很矛盾。一方面，我很爱他，不想失去我们的婚姻；另一方面，我很难忘记这件事情，重新建立信任。
user: 那我们现在应该怎么做？
user: 好的，我会努力去尝试。谢谢你的帮助。<|im_end|>
<|im_start|>assistant
{"depression_level": 1, "anxiety_level": 2, "risk_flag": "none", "student_distress_score": 6}<|im_end|>

label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4913, 450, 4011, 8274, 788, 220, 16, 11, 330, 276, 16308, 8274, 788, 220, 17, 11, 330, 80943, 10933, 788, 330, 6697, 497, 330, 12038, 16031, 673, 10405, 788, 220, 21, 92, 151645, 198]
labels:
{"depression_level": 1, "anxiety_level": 2, "risk_flag": "none", "student_distress_score": 6}<|im_end|>

[INFO|2025-11-24 16:14:24] llamafactory.model.model_utils.quantization:143 >> Quantizing model to 4 bit with bitsandbytes.
[INFO|2025-11-24 16:14:24] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
[INFO|2025-11-24 16:14:28] llamafactory.model.model_utils.checkpointing:143 >> Upcasting layernorm weights in float32.
[INFO|2025-11-24 16:14:28] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
[INFO|2025-11-24 16:14:28] llamafactory.model.model_utils.checkpointing:143 >> Upcasting lm_head outputs in float32.
[INFO|2025-11-24 16:14:28] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-11-24 16:14:28] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.
[INFO|2025-11-24 16:14:28] llamafactory.model.adapter:143 >> Fine-tuning method: DoRA
[INFO|2025-11-24 16:14:28] llamafactory.model.model_utils.misc:143 >> Found linear modules: o_proj,gate_proj,q_proj,v_proj,k_proj,up_proj,down_proj
