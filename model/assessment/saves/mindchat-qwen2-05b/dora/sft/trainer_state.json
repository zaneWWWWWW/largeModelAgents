{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 1000,
  "global_step": 1716,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017497812773403325,
      "grad_norm": 2.6342227458953857,
      "learning_rate": 5.232558139534884e-06,
      "loss": 0.5228,
      "step": 10
    },
    {
      "epoch": 0.03499562554680665,
      "grad_norm": 1.6951842308044434,
      "learning_rate": 1.1046511627906977e-05,
      "loss": 0.4027,
      "step": 20
    },
    {
      "epoch": 0.05249343832020997,
      "grad_norm": 0.4808723032474518,
      "learning_rate": 1.686046511627907e-05,
      "loss": 0.233,
      "step": 30
    },
    {
      "epoch": 0.0699912510936133,
      "grad_norm": 0.4144045412540436,
      "learning_rate": 2.2674418604651163e-05,
      "loss": 0.1678,
      "step": 40
    },
    {
      "epoch": 0.08748906386701662,
      "grad_norm": 0.3231678605079651,
      "learning_rate": 2.848837209302326e-05,
      "loss": 0.1503,
      "step": 50
    },
    {
      "epoch": 0.10498687664041995,
      "grad_norm": 0.35949158668518066,
      "learning_rate": 3.430232558139535e-05,
      "loss": 0.1415,
      "step": 60
    },
    {
      "epoch": 0.12248468941382328,
      "grad_norm": 0.4087023138999939,
      "learning_rate": 4.0116279069767444e-05,
      "loss": 0.1371,
      "step": 70
    },
    {
      "epoch": 0.1399825021872266,
      "grad_norm": 0.4660230576992035,
      "learning_rate": 4.593023255813954e-05,
      "loss": 0.1236,
      "step": 80
    },
    {
      "epoch": 0.15748031496062992,
      "grad_norm": 0.5848084688186646,
      "learning_rate": 5.1744186046511636e-05,
      "loss": 0.1195,
      "step": 90
    },
    {
      "epoch": 0.17497812773403323,
      "grad_norm": 1.551065444946289,
      "learning_rate": 5.755813953488373e-05,
      "loss": 0.1244,
      "step": 100
    },
    {
      "epoch": 0.19247594050743658,
      "grad_norm": 0.6121097207069397,
      "learning_rate": 6.337209302325582e-05,
      "loss": 0.1144,
      "step": 110
    },
    {
      "epoch": 0.2099737532808399,
      "grad_norm": 0.5920374989509583,
      "learning_rate": 6.918604651162791e-05,
      "loss": 0.1138,
      "step": 120
    },
    {
      "epoch": 0.2274715660542432,
      "grad_norm": 0.5796317458152771,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.1105,
      "step": 130
    },
    {
      "epoch": 0.24496937882764655,
      "grad_norm": 0.3686249852180481,
      "learning_rate": 8.081395348837209e-05,
      "loss": 0.1088,
      "step": 140
    },
    {
      "epoch": 0.26246719160104987,
      "grad_norm": 0.45001527667045593,
      "learning_rate": 8.662790697674419e-05,
      "loss": 0.106,
      "step": 150
    },
    {
      "epoch": 0.2799650043744532,
      "grad_norm": 0.49456679821014404,
      "learning_rate": 9.244186046511628e-05,
      "loss": 0.1061,
      "step": 160
    },
    {
      "epoch": 0.2974628171478565,
      "grad_norm": 0.5320540070533752,
      "learning_rate": 9.825581395348838e-05,
      "loss": 0.1054,
      "step": 170
    },
    {
      "epoch": 0.31496062992125984,
      "grad_norm": 0.6110552549362183,
      "learning_rate": 9.999492852953918e-05,
      "loss": 0.1034,
      "step": 180
    },
    {
      "epoch": 0.3324584426946632,
      "grad_norm": 0.27508652210235596,
      "learning_rate": 9.997009115083239e-05,
      "loss": 0.1001,
      "step": 190
    },
    {
      "epoch": 0.34995625546806647,
      "grad_norm": 0.49575692415237427,
      "learning_rate": 9.992456663888425e-05,
      "loss": 0.0911,
      "step": 200
    },
    {
      "epoch": 0.3674540682414698,
      "grad_norm": 0.28320929408073425,
      "learning_rate": 9.985837384040138e-05,
      "loss": 0.0911,
      "step": 210
    },
    {
      "epoch": 0.38495188101487315,
      "grad_norm": 0.4122617244720459,
      "learning_rate": 9.97715401585605e-05,
      "loss": 0.0919,
      "step": 220
    },
    {
      "epoch": 0.40244969378827644,
      "grad_norm": 0.30446362495422363,
      "learning_rate": 9.966410154166403e-05,
      "loss": 0.0957,
      "step": 230
    },
    {
      "epoch": 0.4199475065616798,
      "grad_norm": 0.25750648975372314,
      "learning_rate": 9.953610246825765e-05,
      "loss": 0.0905,
      "step": 240
    },
    {
      "epoch": 0.4374453193350831,
      "grad_norm": 0.30756813287734985,
      "learning_rate": 9.938759592871671e-05,
      "loss": 0.0945,
      "step": 250
    },
    {
      "epoch": 0.4549431321084864,
      "grad_norm": 0.3403764069080353,
      "learning_rate": 9.921864340330871e-05,
      "loss": 0.0901,
      "step": 260
    },
    {
      "epoch": 0.47244094488188976,
      "grad_norm": 0.3465958833694458,
      "learning_rate": 9.902931483674105e-05,
      "loss": 0.0889,
      "step": 270
    },
    {
      "epoch": 0.4899387576552931,
      "grad_norm": 0.7710466384887695,
      "learning_rate": 9.881968860920463e-05,
      "loss": 0.0883,
      "step": 280
    },
    {
      "epoch": 0.5074365704286964,
      "grad_norm": 0.42243829369544983,
      "learning_rate": 9.858985150392515e-05,
      "loss": 0.0864,
      "step": 290
    },
    {
      "epoch": 0.5249343832020997,
      "grad_norm": 0.1750710904598236,
      "learning_rate": 9.833989867123577e-05,
      "loss": 0.0904,
      "step": 300
    },
    {
      "epoch": 0.5424321959755031,
      "grad_norm": 0.3925444483757019,
      "learning_rate": 9.806993358918578e-05,
      "loss": 0.0872,
      "step": 310
    },
    {
      "epoch": 0.5599300087489064,
      "grad_norm": 0.46770793199539185,
      "learning_rate": 9.778006802070162e-05,
      "loss": 0.0874,
      "step": 320
    },
    {
      "epoch": 0.5774278215223098,
      "grad_norm": 0.3475155830383301,
      "learning_rate": 9.74704219673182e-05,
      "loss": 0.0864,
      "step": 330
    },
    {
      "epoch": 0.594925634295713,
      "grad_norm": 0.2406759411096573,
      "learning_rate": 9.71411236194994e-05,
      "loss": 0.0871,
      "step": 340
    },
    {
      "epoch": 0.6124234470691163,
      "grad_norm": 0.3000398874282837,
      "learning_rate": 9.679230930356841e-05,
      "loss": 0.0824,
      "step": 350
    },
    {
      "epoch": 0.6299212598425197,
      "grad_norm": 0.3061961233615875,
      "learning_rate": 9.642412342527006e-05,
      "loss": 0.0812,
      "step": 360
    },
    {
      "epoch": 0.647419072615923,
      "grad_norm": 0.45840272307395935,
      "learning_rate": 9.603671840998811e-05,
      "loss": 0.0842,
      "step": 370
    },
    {
      "epoch": 0.6649168853893264,
      "grad_norm": 0.33059102296829224,
      "learning_rate": 9.563025463964275e-05,
      "loss": 0.09,
      "step": 380
    },
    {
      "epoch": 0.6824146981627297,
      "grad_norm": 0.24448150396347046,
      "learning_rate": 9.520490038629394e-05,
      "loss": 0.09,
      "step": 390
    },
    {
      "epoch": 0.6999125109361329,
      "grad_norm": 0.4601301848888397,
      "learning_rate": 9.476083174247845e-05,
      "loss": 0.0793,
      "step": 400
    },
    {
      "epoch": 0.7174103237095363,
      "grad_norm": 0.2906897962093353,
      "learning_rate": 9.429823254830929e-05,
      "loss": 0.0778,
      "step": 410
    },
    {
      "epoch": 0.7349081364829396,
      "grad_norm": 0.35013410449028015,
      "learning_rate": 9.381729431536758e-05,
      "loss": 0.0768,
      "step": 420
    },
    {
      "epoch": 0.752405949256343,
      "grad_norm": 0.2589696943759918,
      "learning_rate": 9.331821614741876e-05,
      "loss": 0.0793,
      "step": 430
    },
    {
      "epoch": 0.7699037620297463,
      "grad_norm": 0.2554416060447693,
      "learning_rate": 9.280120465798543e-05,
      "loss": 0.0814,
      "step": 440
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 0.1874115914106369,
      "learning_rate": 9.226647388481144e-05,
      "loss": 0.087,
      "step": 450
    },
    {
      "epoch": 0.8048993875765529,
      "grad_norm": 0.3026027977466583,
      "learning_rate": 9.171424520125227e-05,
      "loss": 0.0821,
      "step": 460
    },
    {
      "epoch": 0.8223972003499562,
      "grad_norm": 0.2843359410762787,
      "learning_rate": 9.11447472246287e-05,
      "loss": 0.0777,
      "step": 470
    },
    {
      "epoch": 0.8398950131233596,
      "grad_norm": 0.26757439970970154,
      "learning_rate": 9.055821572158133e-05,
      "loss": 0.0817,
      "step": 480
    },
    {
      "epoch": 0.8573928258967629,
      "grad_norm": 0.2570665180683136,
      "learning_rate": 8.995489351046562e-05,
      "loss": 0.0799,
      "step": 490
    },
    {
      "epoch": 0.8748906386701663,
      "grad_norm": 0.428140252828598,
      "learning_rate": 8.933503036082733e-05,
      "loss": 0.0839,
      "step": 500
    },
    {
      "epoch": 0.8923884514435696,
      "grad_norm": 0.29671531915664673,
      "learning_rate": 8.86988828900004e-05,
      "loss": 0.0805,
      "step": 510
    },
    {
      "epoch": 0.9098862642169728,
      "grad_norm": 0.27014756202697754,
      "learning_rate": 8.804671445686985e-05,
      "loss": 0.0777,
      "step": 520
    },
    {
      "epoch": 0.9273840769903762,
      "grad_norm": 0.24565239250659943,
      "learning_rate": 8.737879505284378e-05,
      "loss": 0.0779,
      "step": 530
    },
    {
      "epoch": 0.9448818897637795,
      "grad_norm": 0.4152669906616211,
      "learning_rate": 8.66954011900795e-05,
      "loss": 0.0827,
      "step": 540
    },
    {
      "epoch": 0.9623797025371829,
      "grad_norm": 0.3326442241668701,
      "learning_rate": 8.59968157870102e-05,
      "loss": 0.0803,
      "step": 550
    },
    {
      "epoch": 0.9798775153105862,
      "grad_norm": 0.21888461709022522,
      "learning_rate": 8.52833280512195e-05,
      "loss": 0.0816,
      "step": 560
    },
    {
      "epoch": 0.9973753280839895,
      "grad_norm": 0.35970762372016907,
      "learning_rate": 8.455523335971223e-05,
      "loss": 0.0794,
      "step": 570
    },
    {
      "epoch": 1.0139982502187226,
      "grad_norm": 0.40218546986579895,
      "learning_rate": 8.381283313663129e-05,
      "loss": 0.0787,
      "step": 580
    },
    {
      "epoch": 1.031496062992126,
      "grad_norm": 0.22798562049865723,
      "learning_rate": 8.305643472847095e-05,
      "loss": 0.076,
      "step": 590
    },
    {
      "epoch": 1.0489938757655293,
      "grad_norm": 0.20808547735214233,
      "learning_rate": 8.228635127683836e-05,
      "loss": 0.0765,
      "step": 600
    },
    {
      "epoch": 1.0664916885389326,
      "grad_norm": 0.2919020354747772,
      "learning_rate": 8.150290158881604e-05,
      "loss": 0.0742,
      "step": 610
    },
    {
      "epoch": 1.083989501312336,
      "grad_norm": 0.3488544523715973,
      "learning_rate": 8.07064100049787e-05,
      "loss": 0.0782,
      "step": 620
    },
    {
      "epoch": 1.1014873140857393,
      "grad_norm": 0.4179922938346863,
      "learning_rate": 7.989720626511947e-05,
      "loss": 0.0773,
      "step": 630
    },
    {
      "epoch": 1.1189851268591426,
      "grad_norm": 0.23894736170768738,
      "learning_rate": 7.907562537174091e-05,
      "loss": 0.0778,
      "step": 640
    },
    {
      "epoch": 1.136482939632546,
      "grad_norm": 0.2857138216495514,
      "learning_rate": 7.824200745136707e-05,
      "loss": 0.0761,
      "step": 650
    },
    {
      "epoch": 1.1539807524059493,
      "grad_norm": 0.35721808671951294,
      "learning_rate": 7.739669761373444e-05,
      "loss": 0.0709,
      "step": 660
    },
    {
      "epoch": 1.1714785651793527,
      "grad_norm": 0.2596260905265808,
      "learning_rate": 7.654004580891997e-05,
      "loss": 0.0758,
      "step": 670
    },
    {
      "epoch": 1.188976377952756,
      "grad_norm": 0.3078050911426544,
      "learning_rate": 7.567240668246496e-05,
      "loss": 0.0777,
      "step": 680
    },
    {
      "epoch": 1.2064741907261591,
      "grad_norm": 0.3487057685852051,
      "learning_rate": 7.479413942855544e-05,
      "loss": 0.0788,
      "step": 690
    },
    {
      "epoch": 1.2239720034995625,
      "grad_norm": 0.22917810082435608,
      "learning_rate": 7.390560764131909e-05,
      "loss": 0.0765,
      "step": 700
    },
    {
      "epoch": 1.2414698162729658,
      "grad_norm": 0.23959755897521973,
      "learning_rate": 7.300717916430088e-05,
      "loss": 0.0722,
      "step": 710
    },
    {
      "epoch": 1.2589676290463692,
      "grad_norm": 0.48387107253074646,
      "learning_rate": 7.209922593817941e-05,
      "loss": 0.0764,
      "step": 720
    },
    {
      "epoch": 1.2764654418197725,
      "grad_norm": 0.25536829233169556,
      "learning_rate": 7.118212384678706e-05,
      "loss": 0.0694,
      "step": 730
    },
    {
      "epoch": 1.2939632545931758,
      "grad_norm": 0.24444185197353363,
      "learning_rate": 7.025625256149769e-05,
      "loss": 0.0757,
      "step": 740
    },
    {
      "epoch": 1.3114610673665792,
      "grad_norm": 0.348590612411499,
      "learning_rate": 6.932199538404646e-05,
      "loss": 0.0776,
      "step": 750
    },
    {
      "epoch": 1.3289588801399825,
      "grad_norm": 0.2950150668621063,
      "learning_rate": 6.837973908784654e-05,
      "loss": 0.0775,
      "step": 760
    },
    {
      "epoch": 1.3464566929133859,
      "grad_norm": 0.3908928632736206,
      "learning_rate": 6.742987375786876e-05,
      "loss": 0.0768,
      "step": 770
    },
    {
      "epoch": 1.3639545056867892,
      "grad_norm": 0.22969897091388702,
      "learning_rate": 6.647279262915006e-05,
      "loss": 0.0703,
      "step": 780
    },
    {
      "epoch": 1.3814523184601923,
      "grad_norm": 0.24255815148353577,
      "learning_rate": 6.55088919239982e-05,
      "loss": 0.0755,
      "step": 790
    },
    {
      "epoch": 1.3989501312335957,
      "grad_norm": 0.2262580394744873,
      "learning_rate": 6.453857068795938e-05,
      "loss": 0.0741,
      "step": 800
    },
    {
      "epoch": 1.416447944006999,
      "grad_norm": 0.2699412703514099,
      "learning_rate": 6.356223062461741e-05,
      "loss": 0.0796,
      "step": 810
    },
    {
      "epoch": 1.4339457567804024,
      "grad_norm": 0.38178950548171997,
      "learning_rate": 6.25802759292922e-05,
      "loss": 0.0725,
      "step": 820
    },
    {
      "epoch": 1.4514435695538057,
      "grad_norm": 0.40539562702178955,
      "learning_rate": 6.159311312170688e-05,
      "loss": 0.0755,
      "step": 830
    },
    {
      "epoch": 1.468941382327209,
      "grad_norm": 0.2158227264881134,
      "learning_rate": 6.060115087769256e-05,
      "loss": 0.0738,
      "step": 840
    },
    {
      "epoch": 1.4864391951006124,
      "grad_norm": 0.3278723955154419,
      "learning_rate": 5.960479986000045e-05,
      "loss": 0.0739,
      "step": 850
    },
    {
      "epoch": 1.5039370078740157,
      "grad_norm": 0.23555001616477966,
      "learning_rate": 5.860447254829158e-05,
      "loss": 0.0761,
      "step": 860
    },
    {
      "epoch": 1.521434820647419,
      "grad_norm": 0.254190057516098,
      "learning_rate": 5.760058306837414e-05,
      "loss": 0.0732,
      "step": 870
    },
    {
      "epoch": 1.5389326334208224,
      "grad_norm": 0.2131957709789276,
      "learning_rate": 5.659354702075935e-05,
      "loss": 0.0754,
      "step": 880
    },
    {
      "epoch": 1.5564304461942258,
      "grad_norm": 0.23241843283176422,
      "learning_rate": 5.558378130860707e-05,
      "loss": 0.0755,
      "step": 890
    },
    {
      "epoch": 1.5739282589676291,
      "grad_norm": 0.26919373869895935,
      "learning_rate": 5.4571703965131695e-05,
      "loss": 0.0713,
      "step": 900
    },
    {
      "epoch": 1.5914260717410325,
      "grad_norm": 0.28385794162750244,
      "learning_rate": 5.3557733980540635e-05,
      "loss": 0.0712,
      "step": 910
    },
    {
      "epoch": 1.6089238845144358,
      "grad_norm": 0.22070147097110748,
      "learning_rate": 5.254229112857636e-05,
      "loss": 0.0691,
      "step": 920
    },
    {
      "epoch": 1.6264216972878391,
      "grad_norm": 0.46119120717048645,
      "learning_rate": 5.1525795792734144e-05,
      "loss": 0.0728,
      "step": 930
    },
    {
      "epoch": 1.6439195100612425,
      "grad_norm": 0.21767249703407288,
      "learning_rate": 5.050866879222742e-05,
      "loss": 0.0717,
      "step": 940
    },
    {
      "epoch": 1.6614173228346458,
      "grad_norm": 0.23991064727306366,
      "learning_rate": 4.949133120777259e-05,
      "loss": 0.0684,
      "step": 950
    },
    {
      "epoch": 1.678915135608049,
      "grad_norm": 0.2939630150794983,
      "learning_rate": 4.8474204207265854e-05,
      "loss": 0.0708,
      "step": 960
    },
    {
      "epoch": 1.6964129483814523,
      "grad_norm": 0.26071271300315857,
      "learning_rate": 4.745770887142366e-05,
      "loss": 0.0733,
      "step": 970
    },
    {
      "epoch": 1.7139107611548556,
      "grad_norm": 0.20356711745262146,
      "learning_rate": 4.644226601945938e-05,
      "loss": 0.0758,
      "step": 980
    },
    {
      "epoch": 1.731408573928259,
      "grad_norm": 0.28752267360687256,
      "learning_rate": 4.5428296034868324e-05,
      "loss": 0.0755,
      "step": 990
    },
    {
      "epoch": 1.7489063867016623,
      "grad_norm": 0.29820841550827026,
      "learning_rate": 4.441621869139293e-05,
      "loss": 0.0753,
      "step": 1000
    },
    {
      "epoch": 1.7489063867016623,
      "eval_loss": 0.07409386336803436,
      "eval_runtime": 43.1955,
      "eval_samples_per_second": 22.294,
      "eval_steps_per_second": 2.801,
      "step": 1000
    },
    {
      "epoch": 1.7664041994750657,
      "grad_norm": 0.21687325835227966,
      "learning_rate": 4.340645297924064e-05,
      "loss": 0.0698,
      "step": 1010
    },
    {
      "epoch": 1.7839020122484688,
      "grad_norm": 0.2415323406457901,
      "learning_rate": 4.2399416931625894e-05,
      "loss": 0.0725,
      "step": 1020
    },
    {
      "epoch": 1.8013998250218721,
      "grad_norm": 0.2155916392803192,
      "learning_rate": 4.139552745170843e-05,
      "loss": 0.0748,
      "step": 1030
    },
    {
      "epoch": 1.8188976377952755,
      "grad_norm": 0.22129733860492706,
      "learning_rate": 4.0395200139999566e-05,
      "loss": 0.0703,
      "step": 1040
    },
    {
      "epoch": 1.8363954505686788,
      "grad_norm": 0.24352695047855377,
      "learning_rate": 3.939884912230746e-05,
      "loss": 0.0716,
      "step": 1050
    },
    {
      "epoch": 1.8538932633420822,
      "grad_norm": 0.3684723973274231,
      "learning_rate": 3.840688687829312e-05,
      "loss": 0.0729,
      "step": 1060
    },
    {
      "epoch": 1.8713910761154855,
      "grad_norm": 0.25852376222610474,
      "learning_rate": 3.7419724070707806e-05,
      "loss": 0.0733,
      "step": 1070
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.24803267419338226,
      "learning_rate": 3.64377693753826e-05,
      "loss": 0.0733,
      "step": 1080
    },
    {
      "epoch": 1.9063867016622922,
      "grad_norm": 0.24424618482589722,
      "learning_rate": 3.546142931204062e-05,
      "loss": 0.0722,
      "step": 1090
    },
    {
      "epoch": 1.9238845144356955,
      "grad_norm": 0.29537174105644226,
      "learning_rate": 3.449110807600182e-05,
      "loss": 0.0685,
      "step": 1100
    },
    {
      "epoch": 1.9413823272090989,
      "grad_norm": 0.2558594346046448,
      "learning_rate": 3.352720737084994e-05,
      "loss": 0.071,
      "step": 1110
    },
    {
      "epoch": 1.9588801399825022,
      "grad_norm": 0.20249226689338684,
      "learning_rate": 3.257012624213126e-05,
      "loss": 0.0725,
      "step": 1120
    },
    {
      "epoch": 1.9763779527559056,
      "grad_norm": 0.41365835070610046,
      "learning_rate": 3.162026091215347e-05,
      "loss": 0.064,
      "step": 1130
    },
    {
      "epoch": 1.993875765529309,
      "grad_norm": 0.2042560577392578,
      "learning_rate": 3.067800461595355e-05,
      "loss": 0.0704,
      "step": 1140
    },
    {
      "epoch": 2.010498687664042,
      "grad_norm": 0.20796528458595276,
      "learning_rate": 2.9743747438502316e-05,
      "loss": 0.0698,
      "step": 1150
    },
    {
      "epoch": 2.027996500437445,
      "grad_norm": 0.29902905225753784,
      "learning_rate": 2.8817876153212958e-05,
      "loss": 0.0644,
      "step": 1160
    },
    {
      "epoch": 2.0454943132108485,
      "grad_norm": 0.20892509818077087,
      "learning_rate": 2.7900774061820613e-05,
      "loss": 0.0711,
      "step": 1170
    },
    {
      "epoch": 2.062992125984252,
      "grad_norm": 0.2548845410346985,
      "learning_rate": 2.6992820835699133e-05,
      "loss": 0.069,
      "step": 1180
    },
    {
      "epoch": 2.080489938757655,
      "grad_norm": 0.1987486183643341,
      "learning_rate": 2.609439235868092e-05,
      "loss": 0.0685,
      "step": 1190
    },
    {
      "epoch": 2.0979877515310585,
      "grad_norm": 0.24897199869155884,
      "learning_rate": 2.5205860571444563e-05,
      "loss": 0.0619,
      "step": 1200
    },
    {
      "epoch": 2.115485564304462,
      "grad_norm": 0.2879839837551117,
      "learning_rate": 2.4327593317535045e-05,
      "loss": 0.0658,
      "step": 1210
    },
    {
      "epoch": 2.1329833770778652,
      "grad_norm": 0.32851848006248474,
      "learning_rate": 2.3459954191080065e-05,
      "loss": 0.067,
      "step": 1220
    },
    {
      "epoch": 2.1504811898512686,
      "grad_norm": 0.39777591824531555,
      "learning_rate": 2.2603302386265567e-05,
      "loss": 0.0661,
      "step": 1230
    },
    {
      "epoch": 2.167979002624672,
      "grad_norm": 0.24693024158477783,
      "learning_rate": 2.175799254863294e-05,
      "loss": 0.0682,
      "step": 1240
    },
    {
      "epoch": 2.1854768153980753,
      "grad_norm": 0.403402715921402,
      "learning_rate": 2.092437462825908e-05,
      "loss": 0.0688,
      "step": 1250
    },
    {
      "epoch": 2.2029746281714786,
      "grad_norm": 0.2440442591905594,
      "learning_rate": 2.010279373488053e-05,
      "loss": 0.0677,
      "step": 1260
    },
    {
      "epoch": 2.220472440944882,
      "grad_norm": 0.23415102064609528,
      "learning_rate": 1.9293589995021337e-05,
      "loss": 0.0697,
      "step": 1270
    },
    {
      "epoch": 2.2379702537182853,
      "grad_norm": 0.2710503935813904,
      "learning_rate": 1.8497098411183973e-05,
      "loss": 0.0661,
      "step": 1280
    },
    {
      "epoch": 2.2554680664916886,
      "grad_norm": 0.30418142676353455,
      "learning_rate": 1.771364872316163e-05,
      "loss": 0.067,
      "step": 1290
    },
    {
      "epoch": 2.272965879265092,
      "grad_norm": 0.24616460502147675,
      "learning_rate": 1.6943565271529045e-05,
      "loss": 0.0654,
      "step": 1300
    },
    {
      "epoch": 2.2904636920384953,
      "grad_norm": 0.3490281105041504,
      "learning_rate": 1.6187166863368713e-05,
      "loss": 0.0684,
      "step": 1310
    },
    {
      "epoch": 2.3079615048118987,
      "grad_norm": 0.3303692936897278,
      "learning_rate": 1.544476664028779e-05,
      "loss": 0.0683,
      "step": 1320
    },
    {
      "epoch": 2.325459317585302,
      "grad_norm": 0.26147621870040894,
      "learning_rate": 1.4716671948780513e-05,
      "loss": 0.0647,
      "step": 1330
    },
    {
      "epoch": 2.3429571303587053,
      "grad_norm": 0.22499649226665497,
      "learning_rate": 1.40031842129898e-05,
      "loss": 0.0652,
      "step": 1340
    },
    {
      "epoch": 2.3604549431321082,
      "grad_norm": 0.29291996359825134,
      "learning_rate": 1.33045988099205e-05,
      "loss": 0.0627,
      "step": 1350
    },
    {
      "epoch": 2.377952755905512,
      "grad_norm": 0.2038605511188507,
      "learning_rate": 1.262120494715624e-05,
      "loss": 0.0672,
      "step": 1360
    },
    {
      "epoch": 2.395450568678915,
      "grad_norm": 0.26272958517074585,
      "learning_rate": 1.195328554313016e-05,
      "loss": 0.0656,
      "step": 1370
    },
    {
      "epoch": 2.4129483814523183,
      "grad_norm": 0.3221382796764374,
      "learning_rate": 1.130111710999961e-05,
      "loss": 0.066,
      "step": 1380
    },
    {
      "epoch": 2.4304461942257216,
      "grad_norm": 0.32177722454071045,
      "learning_rate": 1.0664969639172672e-05,
      "loss": 0.0624,
      "step": 1390
    },
    {
      "epoch": 2.447944006999125,
      "grad_norm": 0.3021818995475769,
      "learning_rate": 1.0045106489534389e-05,
      "loss": 0.0676,
      "step": 1400
    },
    {
      "epoch": 2.4654418197725283,
      "grad_norm": 0.25223758816719055,
      "learning_rate": 9.441784278418686e-06,
      "loss": 0.0669,
      "step": 1410
    },
    {
      "epoch": 2.4829396325459316,
      "grad_norm": 0.29470646381378174,
      "learning_rate": 8.85525277537132e-06,
      "loss": 0.066,
      "step": 1420
    },
    {
      "epoch": 2.500437445319335,
      "grad_norm": 0.42797228693962097,
      "learning_rate": 8.285754798747736e-06,
      "loss": 0.0627,
      "step": 1430
    },
    {
      "epoch": 2.5179352580927383,
      "grad_norm": 0.2850504517555237,
      "learning_rate": 7.733526115188567e-06,
      "loss": 0.0659,
      "step": 1440
    },
    {
      "epoch": 2.5354330708661417,
      "grad_norm": 0.2884679436683655,
      "learning_rate": 7.198795342014575e-06,
      "loss": 0.068,
      "step": 1450
    },
    {
      "epoch": 2.552930883639545,
      "grad_norm": 0.21456816792488098,
      "learning_rate": 6.681783852581252e-06,
      "loss": 0.0633,
      "step": 1460
    },
    {
      "epoch": 2.5704286964129484,
      "grad_norm": 0.2550642192363739,
      "learning_rate": 6.182705684632429e-06,
      "loss": 0.0654,
      "step": 1470
    },
    {
      "epoch": 2.5879265091863517,
      "grad_norm": 0.31497493386268616,
      "learning_rate": 5.701767451690726e-06,
      "loss": 0.0638,
      "step": 1480
    },
    {
      "epoch": 2.605424321959755,
      "grad_norm": 0.2880280315876007,
      "learning_rate": 5.239168257521549e-06,
      "loss": 0.0637,
      "step": 1490
    },
    {
      "epoch": 2.6229221347331584,
      "grad_norm": 0.27088236808776855,
      "learning_rate": 4.7950996137060666e-06,
      "loss": 0.0635,
      "step": 1500
    },
    {
      "epoch": 2.6404199475065617,
      "grad_norm": 0.3014012277126312,
      "learning_rate": 4.369745360357258e-06,
      "loss": 0.0641,
      "step": 1510
    },
    {
      "epoch": 2.657917760279965,
      "grad_norm": 0.3318765163421631,
      "learning_rate": 3.963281590011892e-06,
      "loss": 0.0693,
      "step": 1520
    },
    {
      "epoch": 2.6754155730533684,
      "grad_norm": 0.24884456396102905,
      "learning_rate": 3.575876574729947e-06,
      "loss": 0.064,
      "step": 1530
    },
    {
      "epoch": 2.6929133858267718,
      "grad_norm": 0.28027772903442383,
      "learning_rate": 3.207690696431581e-06,
      "loss": 0.0646,
      "step": 1540
    },
    {
      "epoch": 2.710411198600175,
      "grad_norm": 0.23885922133922577,
      "learning_rate": 2.858876380500608e-06,
      "loss": 0.0638,
      "step": 1550
    },
    {
      "epoch": 2.7279090113735784,
      "grad_norm": 0.2851178050041199,
      "learning_rate": 2.5295780326818063e-06,
      "loss": 0.0657,
      "step": 1560
    },
    {
      "epoch": 2.745406824146982,
      "grad_norm": 0.277808278799057,
      "learning_rate": 2.2199319792983896e-06,
      "loss": 0.0649,
      "step": 1570
    },
    {
      "epoch": 2.7629046369203847,
      "grad_norm": 0.2562333345413208,
      "learning_rate": 1.9300664108142298e-06,
      "loss": 0.0674,
      "step": 1580
    },
    {
      "epoch": 2.7804024496937885,
      "grad_norm": 0.23543137311935425,
      "learning_rate": 1.6601013287642297e-06,
      "loss": 0.0615,
      "step": 1590
    },
    {
      "epoch": 2.7979002624671914,
      "grad_norm": 0.31624266505241394,
      "learning_rate": 1.410148496074859e-06,
      "loss": 0.0632,
      "step": 1600
    },
    {
      "epoch": 2.815398075240595,
      "grad_norm": 0.2809314727783203,
      "learning_rate": 1.1803113907953855e-06,
      "loss": 0.0639,
      "step": 1610
    },
    {
      "epoch": 2.832895888013998,
      "grad_norm": 0.282728374004364,
      "learning_rate": 9.706851632589498e-07,
      "loss": 0.0655,
      "step": 1620
    },
    {
      "epoch": 2.850393700787402,
      "grad_norm": 0.2990603446960449,
      "learning_rate": 7.813565966912905e-07,
      "loss": 0.0702,
      "step": 1630
    },
    {
      "epoch": 2.8678915135608047,
      "grad_norm": 0.36267897486686707,
      "learning_rate": 6.124040712832846e-07,
      "loss": 0.0685,
      "step": 1640
    },
    {
      "epoch": 2.885389326334208,
      "grad_norm": 0.31816384196281433,
      "learning_rate": 4.638975317423522e-07,
      "loss": 0.0657,
      "step": 1650
    },
    {
      "epoch": 2.9028871391076114,
      "grad_norm": 0.32144126296043396,
      "learning_rate": 3.358984583359703e-07,
      "loss": 0.0643,
      "step": 1660
    },
    {
      "epoch": 2.9203849518810148,
      "grad_norm": 0.3092522919178009,
      "learning_rate": 2.2845984143949895e-07,
      "loss": 0.064,
      "step": 1670
    },
    {
      "epoch": 2.937882764654418,
      "grad_norm": 0.22310875356197357,
      "learning_rate": 1.4162615959863457e-07,
      "loss": 0.0626,
      "step": 1680
    },
    {
      "epoch": 2.9553805774278215,
      "grad_norm": 0.39799514412879944,
      "learning_rate": 7.543336111575094e-08,
      "loss": 0.066,
      "step": 1690
    },
    {
      "epoch": 2.972878390201225,
      "grad_norm": 0.2542976140975952,
      "learning_rate": 2.990884916763137e-08,
      "loss": 0.07,
      "step": 1700
    },
    {
      "epoch": 2.990376202974628,
      "grad_norm": 0.32836732268333435,
      "learning_rate": 5.071470460832339e-09,
      "loss": 0.067,
      "step": 1710
    },
    {
      "epoch": 3.0,
      "step": 1716,
      "total_flos": 9.254887060129382e+16,
      "train_loss": 0.08343932282674563,
      "train_runtime": 10125.1049,
      "train_samples_per_second": 5.418,
      "train_steps_per_second": 0.169
    }
  ],
  "logging_steps": 10,
  "max_steps": 1716,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.254887060129382e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
