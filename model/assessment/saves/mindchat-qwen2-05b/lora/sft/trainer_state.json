{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 1000,
  "global_step": 1716,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017497812773403325,
      "grad_norm": 2.7262532711029053,
      "learning_rate": 5.232558139534884e-06,
      "loss": 0.5468,
      "step": 10
    },
    {
      "epoch": 0.03499562554680665,
      "grad_norm": 1.7796484231948853,
      "learning_rate": 1.1046511627906977e-05,
      "loss": 0.4255,
      "step": 20
    },
    {
      "epoch": 0.05249343832020997,
      "grad_norm": 0.4850206971168518,
      "learning_rate": 1.686046511627907e-05,
      "loss": 0.2429,
      "step": 30
    },
    {
      "epoch": 0.0699912510936133,
      "grad_norm": 0.43001922965049744,
      "learning_rate": 2.2674418604651163e-05,
      "loss": 0.1692,
      "step": 40
    },
    {
      "epoch": 0.08748906386701662,
      "grad_norm": 0.3702583312988281,
      "learning_rate": 2.848837209302326e-05,
      "loss": 0.1513,
      "step": 50
    },
    {
      "epoch": 0.10498687664041995,
      "grad_norm": 0.3907802402973175,
      "learning_rate": 3.430232558139535e-05,
      "loss": 0.1427,
      "step": 60
    },
    {
      "epoch": 0.12248468941382328,
      "grad_norm": 0.43508535623550415,
      "learning_rate": 4.0116279069767444e-05,
      "loss": 0.1392,
      "step": 70
    },
    {
      "epoch": 0.1399825021872266,
      "grad_norm": 0.4638979136943817,
      "learning_rate": 4.593023255813954e-05,
      "loss": 0.1258,
      "step": 80
    },
    {
      "epoch": 0.15748031496062992,
      "grad_norm": 0.7222078442573547,
      "learning_rate": 5.1744186046511636e-05,
      "loss": 0.121,
      "step": 90
    },
    {
      "epoch": 0.17497812773403323,
      "grad_norm": 0.9610591530799866,
      "learning_rate": 5.755813953488373e-05,
      "loss": 0.1269,
      "step": 100
    },
    {
      "epoch": 0.19247594050743658,
      "grad_norm": 0.6405833959579468,
      "learning_rate": 6.337209302325582e-05,
      "loss": 0.1148,
      "step": 110
    },
    {
      "epoch": 0.2099737532808399,
      "grad_norm": 0.7796623110771179,
      "learning_rate": 6.918604651162791e-05,
      "loss": 0.1159,
      "step": 120
    },
    {
      "epoch": 0.2274715660542432,
      "grad_norm": 0.5455369353294373,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.1131,
      "step": 130
    },
    {
      "epoch": 0.24496937882764655,
      "grad_norm": 0.40003031492233276,
      "learning_rate": 8.081395348837209e-05,
      "loss": 0.1105,
      "step": 140
    },
    {
      "epoch": 0.26246719160104987,
      "grad_norm": 0.5200830101966858,
      "learning_rate": 8.662790697674419e-05,
      "loss": 0.1084,
      "step": 150
    },
    {
      "epoch": 0.2799650043744532,
      "grad_norm": 0.6509326100349426,
      "learning_rate": 9.244186046511628e-05,
      "loss": 0.11,
      "step": 160
    },
    {
      "epoch": 0.2974628171478565,
      "grad_norm": 0.4516127407550812,
      "learning_rate": 9.825581395348838e-05,
      "loss": 0.107,
      "step": 170
    },
    {
      "epoch": 0.31496062992125984,
      "grad_norm": 0.6017825603485107,
      "learning_rate": 9.999492852953918e-05,
      "loss": 0.1042,
      "step": 180
    },
    {
      "epoch": 0.3324584426946632,
      "grad_norm": 0.2938265800476074,
      "learning_rate": 9.997009115083239e-05,
      "loss": 0.1018,
      "step": 190
    },
    {
      "epoch": 0.34995625546806647,
      "grad_norm": 0.4176541268825531,
      "learning_rate": 9.992456663888425e-05,
      "loss": 0.0927,
      "step": 200
    },
    {
      "epoch": 0.3674540682414698,
      "grad_norm": 0.4947246313095093,
      "learning_rate": 9.985837384040138e-05,
      "loss": 0.0923,
      "step": 210
    },
    {
      "epoch": 0.38495188101487315,
      "grad_norm": 0.2539445161819458,
      "learning_rate": 9.97715401585605e-05,
      "loss": 0.0926,
      "step": 220
    },
    {
      "epoch": 0.40244969378827644,
      "grad_norm": 0.48263412714004517,
      "learning_rate": 9.966410154166403e-05,
      "loss": 0.0957,
      "step": 230
    },
    {
      "epoch": 0.4199475065616798,
      "grad_norm": 0.26502326130867004,
      "learning_rate": 9.953610246825765e-05,
      "loss": 0.092,
      "step": 240
    },
    {
      "epoch": 0.4374453193350831,
      "grad_norm": 0.33158156275749207,
      "learning_rate": 9.938759592871671e-05,
      "loss": 0.0965,
      "step": 250
    },
    {
      "epoch": 0.4549431321084864,
      "grad_norm": 0.3395930528640747,
      "learning_rate": 9.921864340330871e-05,
      "loss": 0.0925,
      "step": 260
    },
    {
      "epoch": 0.47244094488188976,
      "grad_norm": 0.3837187886238098,
      "learning_rate": 9.902931483674105e-05,
      "loss": 0.0921,
      "step": 270
    },
    {
      "epoch": 0.4899387576552931,
      "grad_norm": 0.6402357816696167,
      "learning_rate": 9.881968860920463e-05,
      "loss": 0.0895,
      "step": 280
    },
    {
      "epoch": 0.5074365704286964,
      "grad_norm": 0.32064560055732727,
      "learning_rate": 9.858985150392515e-05,
      "loss": 0.0864,
      "step": 290
    },
    {
      "epoch": 0.5249343832020997,
      "grad_norm": 0.17896711826324463,
      "learning_rate": 9.833989867123577e-05,
      "loss": 0.0911,
      "step": 300
    },
    {
      "epoch": 0.5424321959755031,
      "grad_norm": 0.3827873468399048,
      "learning_rate": 9.806993358918578e-05,
      "loss": 0.0886,
      "step": 310
    },
    {
      "epoch": 0.5599300087489064,
      "grad_norm": 0.43563368916511536,
      "learning_rate": 9.778006802070162e-05,
      "loss": 0.0887,
      "step": 320
    },
    {
      "epoch": 0.5774278215223098,
      "grad_norm": 0.312323659658432,
      "learning_rate": 9.74704219673182e-05,
      "loss": 0.0868,
      "step": 330
    },
    {
      "epoch": 0.594925634295713,
      "grad_norm": 0.2507535219192505,
      "learning_rate": 9.71411236194994e-05,
      "loss": 0.0886,
      "step": 340
    },
    {
      "epoch": 0.6124234470691163,
      "grad_norm": 0.28908446431159973,
      "learning_rate": 9.679230930356841e-05,
      "loss": 0.0836,
      "step": 350
    },
    {
      "epoch": 0.6299212598425197,
      "grad_norm": 0.3464077413082123,
      "learning_rate": 9.642412342527006e-05,
      "loss": 0.0828,
      "step": 360
    },
    {
      "epoch": 0.647419072615923,
      "grad_norm": 0.46217310428619385,
      "learning_rate": 9.603671840998811e-05,
      "loss": 0.0856,
      "step": 370
    },
    {
      "epoch": 0.6649168853893264,
      "grad_norm": 0.2935827076435089,
      "learning_rate": 9.563025463964275e-05,
      "loss": 0.0918,
      "step": 380
    },
    {
      "epoch": 0.6824146981627297,
      "grad_norm": 0.25844982266426086,
      "learning_rate": 9.520490038629394e-05,
      "loss": 0.0915,
      "step": 390
    },
    {
      "epoch": 0.6999125109361329,
      "grad_norm": 0.5009990930557251,
      "learning_rate": 9.476083174247845e-05,
      "loss": 0.0809,
      "step": 400
    },
    {
      "epoch": 0.7174103237095363,
      "grad_norm": 0.3212243616580963,
      "learning_rate": 9.429823254830929e-05,
      "loss": 0.0774,
      "step": 410
    },
    {
      "epoch": 0.7349081364829396,
      "grad_norm": 0.3229734003543854,
      "learning_rate": 9.381729431536758e-05,
      "loss": 0.0775,
      "step": 420
    },
    {
      "epoch": 0.752405949256343,
      "grad_norm": 0.27736178040504456,
      "learning_rate": 9.331821614741876e-05,
      "loss": 0.0789,
      "step": 430
    },
    {
      "epoch": 0.7699037620297463,
      "grad_norm": 0.2735542356967926,
      "learning_rate": 9.280120465798543e-05,
      "loss": 0.0821,
      "step": 440
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 0.2023923695087433,
      "learning_rate": 9.226647388481144e-05,
      "loss": 0.0885,
      "step": 450
    },
    {
      "epoch": 0.8048993875765529,
      "grad_norm": 0.30099934339523315,
      "learning_rate": 9.171424520125227e-05,
      "loss": 0.0833,
      "step": 460
    },
    {
      "epoch": 0.8223972003499562,
      "grad_norm": 0.3210887908935547,
      "learning_rate": 9.11447472246287e-05,
      "loss": 0.078,
      "step": 470
    },
    {
      "epoch": 0.8398950131233596,
      "grad_norm": 0.2904280126094818,
      "learning_rate": 9.055821572158133e-05,
      "loss": 0.0835,
      "step": 480
    },
    {
      "epoch": 0.8573928258967629,
      "grad_norm": 0.2806582450866699,
      "learning_rate": 8.995489351046562e-05,
      "loss": 0.0808,
      "step": 490
    },
    {
      "epoch": 0.8748906386701663,
      "grad_norm": 0.4317253530025482,
      "learning_rate": 8.933503036082733e-05,
      "loss": 0.0844,
      "step": 500
    },
    {
      "epoch": 0.8923884514435696,
      "grad_norm": 0.2887954115867615,
      "learning_rate": 8.86988828900004e-05,
      "loss": 0.0813,
      "step": 510
    },
    {
      "epoch": 0.9098862642169728,
      "grad_norm": 0.2946949601173401,
      "learning_rate": 8.804671445686985e-05,
      "loss": 0.0786,
      "step": 520
    },
    {
      "epoch": 0.9273840769903762,
      "grad_norm": 0.2605745494365692,
      "learning_rate": 8.737879505284378e-05,
      "loss": 0.0785,
      "step": 530
    },
    {
      "epoch": 0.9448818897637795,
      "grad_norm": 0.4172660708427429,
      "learning_rate": 8.66954011900795e-05,
      "loss": 0.0842,
      "step": 540
    },
    {
      "epoch": 0.9623797025371829,
      "grad_norm": 0.32533082365989685,
      "learning_rate": 8.59968157870102e-05,
      "loss": 0.0818,
      "step": 550
    },
    {
      "epoch": 0.9798775153105862,
      "grad_norm": 0.22251231968402863,
      "learning_rate": 8.52833280512195e-05,
      "loss": 0.0826,
      "step": 560
    },
    {
      "epoch": 0.9973753280839895,
      "grad_norm": 0.34368574619293213,
      "learning_rate": 8.455523335971223e-05,
      "loss": 0.0797,
      "step": 570
    },
    {
      "epoch": 1.0139982502187226,
      "grad_norm": 0.3818103075027466,
      "learning_rate": 8.381283313663129e-05,
      "loss": 0.0791,
      "step": 580
    },
    {
      "epoch": 1.031496062992126,
      "grad_norm": 0.24170000851154327,
      "learning_rate": 8.305643472847095e-05,
      "loss": 0.0761,
      "step": 590
    },
    {
      "epoch": 1.0489938757655293,
      "grad_norm": 0.24019356071949005,
      "learning_rate": 8.228635127683836e-05,
      "loss": 0.0772,
      "step": 600
    },
    {
      "epoch": 1.0664916885389326,
      "grad_norm": 0.27143627405166626,
      "learning_rate": 8.150290158881604e-05,
      "loss": 0.0753,
      "step": 610
    },
    {
      "epoch": 1.083989501312336,
      "grad_norm": 0.28509581089019775,
      "learning_rate": 8.07064100049787e-05,
      "loss": 0.078,
      "step": 620
    },
    {
      "epoch": 1.1014873140857393,
      "grad_norm": 0.3574378192424774,
      "learning_rate": 7.989720626511947e-05,
      "loss": 0.0773,
      "step": 630
    },
    {
      "epoch": 1.1189851268591426,
      "grad_norm": 0.219040185213089,
      "learning_rate": 7.907562537174091e-05,
      "loss": 0.0775,
      "step": 640
    },
    {
      "epoch": 1.136482939632546,
      "grad_norm": 0.2658654451370239,
      "learning_rate": 7.824200745136707e-05,
      "loss": 0.0759,
      "step": 650
    },
    {
      "epoch": 1.1539807524059493,
      "grad_norm": 0.363633394241333,
      "learning_rate": 7.739669761373444e-05,
      "loss": 0.0721,
      "step": 660
    },
    {
      "epoch": 1.1714785651793527,
      "grad_norm": 0.24661904573440552,
      "learning_rate": 7.654004580891997e-05,
      "loss": 0.0762,
      "step": 670
    },
    {
      "epoch": 1.188976377952756,
      "grad_norm": 0.32164299488067627,
      "learning_rate": 7.567240668246496e-05,
      "loss": 0.0788,
      "step": 680
    },
    {
      "epoch": 1.2064741907261591,
      "grad_norm": 0.3914615213871002,
      "learning_rate": 7.479413942855544e-05,
      "loss": 0.0788,
      "step": 690
    },
    {
      "epoch": 1.2239720034995625,
      "grad_norm": 0.2887920141220093,
      "learning_rate": 7.390560764131909e-05,
      "loss": 0.0776,
      "step": 700
    },
    {
      "epoch": 1.2414698162729658,
      "grad_norm": 0.2290252447128296,
      "learning_rate": 7.300717916430088e-05,
      "loss": 0.0735,
      "step": 710
    },
    {
      "epoch": 1.2589676290463692,
      "grad_norm": 0.4773871898651123,
      "learning_rate": 7.209922593817941e-05,
      "loss": 0.0771,
      "step": 720
    },
    {
      "epoch": 1.2764654418197725,
      "grad_norm": 0.24581705033779144,
      "learning_rate": 7.118212384678706e-05,
      "loss": 0.0693,
      "step": 730
    },
    {
      "epoch": 1.2939632545931758,
      "grad_norm": 0.25781944394111633,
      "learning_rate": 7.025625256149769e-05,
      "loss": 0.076,
      "step": 740
    },
    {
      "epoch": 1.3114610673665792,
      "grad_norm": 0.3180212080478668,
      "learning_rate": 6.932199538404646e-05,
      "loss": 0.0787,
      "step": 750
    },
    {
      "epoch": 1.3289588801399825,
      "grad_norm": 0.31540337204933167,
      "learning_rate": 6.837973908784654e-05,
      "loss": 0.079,
      "step": 760
    },
    {
      "epoch": 1.3464566929133859,
      "grad_norm": 0.38016578555107117,
      "learning_rate": 6.742987375786876e-05,
      "loss": 0.0784,
      "step": 770
    },
    {
      "epoch": 1.3639545056867892,
      "grad_norm": 0.2275421917438507,
      "learning_rate": 6.647279262915006e-05,
      "loss": 0.071,
      "step": 780
    },
    {
      "epoch": 1.3814523184601923,
      "grad_norm": 0.2577647566795349,
      "learning_rate": 6.55088919239982e-05,
      "loss": 0.0766,
      "step": 790
    },
    {
      "epoch": 1.3989501312335957,
      "grad_norm": 0.23343725502490997,
      "learning_rate": 6.453857068795938e-05,
      "loss": 0.0752,
      "step": 800
    },
    {
      "epoch": 1.416447944006999,
      "grad_norm": 0.2275245636701584,
      "learning_rate": 6.356223062461741e-05,
      "loss": 0.0807,
      "step": 810
    },
    {
      "epoch": 1.4339457567804024,
      "grad_norm": 0.40886491537094116,
      "learning_rate": 6.25802759292922e-05,
      "loss": 0.0733,
      "step": 820
    },
    {
      "epoch": 1.4514435695538057,
      "grad_norm": 0.48014575242996216,
      "learning_rate": 6.159311312170688e-05,
      "loss": 0.076,
      "step": 830
    },
    {
      "epoch": 1.468941382327209,
      "grad_norm": 0.20606844127178192,
      "learning_rate": 6.060115087769256e-05,
      "loss": 0.0739,
      "step": 840
    },
    {
      "epoch": 1.4864391951006124,
      "grad_norm": 0.30351319909095764,
      "learning_rate": 5.960479986000045e-05,
      "loss": 0.0755,
      "step": 850
    },
    {
      "epoch": 1.5039370078740157,
      "grad_norm": 0.2488507479429245,
      "learning_rate": 5.860447254829158e-05,
      "loss": 0.0758,
      "step": 860
    },
    {
      "epoch": 1.521434820647419,
      "grad_norm": 0.25835880637168884,
      "learning_rate": 5.760058306837414e-05,
      "loss": 0.0738,
      "step": 870
    },
    {
      "epoch": 1.5389326334208224,
      "grad_norm": 0.2344609647989273,
      "learning_rate": 5.659354702075935e-05,
      "loss": 0.0749,
      "step": 880
    },
    {
      "epoch": 1.5564304461942258,
      "grad_norm": 0.23222650587558746,
      "learning_rate": 5.558378130860707e-05,
      "loss": 0.0758,
      "step": 890
    },
    {
      "epoch": 1.5739282589676291,
      "grad_norm": 0.29220515489578247,
      "learning_rate": 5.4571703965131695e-05,
      "loss": 0.0722,
      "step": 900
    },
    {
      "epoch": 1.5914260717410325,
      "grad_norm": 0.27246201038360596,
      "learning_rate": 5.3557733980540635e-05,
      "loss": 0.0722,
      "step": 910
    },
    {
      "epoch": 1.6089238845144358,
      "grad_norm": 0.2198297679424286,
      "learning_rate": 5.254229112857636e-05,
      "loss": 0.0701,
      "step": 920
    },
    {
      "epoch": 1.6264216972878391,
      "grad_norm": 0.4187157154083252,
      "learning_rate": 5.1525795792734144e-05,
      "loss": 0.073,
      "step": 930
    },
    {
      "epoch": 1.6439195100612425,
      "grad_norm": 0.22737601399421692,
      "learning_rate": 5.050866879222742e-05,
      "loss": 0.0729,
      "step": 940
    },
    {
      "epoch": 1.6614173228346458,
      "grad_norm": 0.23455514013767242,
      "learning_rate": 4.949133120777259e-05,
      "loss": 0.0702,
      "step": 950
    },
    {
      "epoch": 1.678915135608049,
      "grad_norm": 0.30913516879081726,
      "learning_rate": 4.8474204207265854e-05,
      "loss": 0.0715,
      "step": 960
    },
    {
      "epoch": 1.6964129483814523,
      "grad_norm": 0.26175040006637573,
      "learning_rate": 4.745770887142366e-05,
      "loss": 0.0734,
      "step": 970
    },
    {
      "epoch": 1.7139107611548556,
      "grad_norm": 0.20031005144119263,
      "learning_rate": 4.644226601945938e-05,
      "loss": 0.0757,
      "step": 980
    },
    {
      "epoch": 1.731408573928259,
      "grad_norm": 0.29947155714035034,
      "learning_rate": 4.5428296034868324e-05,
      "loss": 0.0756,
      "step": 990
    },
    {
      "epoch": 1.7489063867016623,
      "grad_norm": 0.3069278299808502,
      "learning_rate": 4.441621869139293e-05,
      "loss": 0.0753,
      "step": 1000
    },
    {
      "epoch": 1.7489063867016623,
      "eval_loss": 0.07433265447616577,
      "eval_runtime": 35.902,
      "eval_samples_per_second": 26.823,
      "eval_steps_per_second": 3.37,
      "step": 1000
    },
    {
      "epoch": 1.7664041994750657,
      "grad_norm": 0.23082099854946136,
      "learning_rate": 4.340645297924064e-05,
      "loss": 0.0697,
      "step": 1010
    },
    {
      "epoch": 1.7839020122484688,
      "grad_norm": 0.261648952960968,
      "learning_rate": 4.2399416931625894e-05,
      "loss": 0.0732,
      "step": 1020
    },
    {
      "epoch": 1.8013998250218721,
      "grad_norm": 0.25459596514701843,
      "learning_rate": 4.139552745170843e-05,
      "loss": 0.0751,
      "step": 1030
    },
    {
      "epoch": 1.8188976377952755,
      "grad_norm": 0.2406006008386612,
      "learning_rate": 4.0395200139999566e-05,
      "loss": 0.0705,
      "step": 1040
    },
    {
      "epoch": 1.8363954505686788,
      "grad_norm": 0.2479419708251953,
      "learning_rate": 3.939884912230746e-05,
      "loss": 0.0709,
      "step": 1050
    },
    {
      "epoch": 1.8538932633420822,
      "grad_norm": 0.35237792134284973,
      "learning_rate": 3.840688687829312e-05,
      "loss": 0.0723,
      "step": 1060
    },
    {
      "epoch": 1.8713910761154855,
      "grad_norm": 0.26565656065940857,
      "learning_rate": 3.7419724070707806e-05,
      "loss": 0.0729,
      "step": 1070
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.2366572916507721,
      "learning_rate": 3.64377693753826e-05,
      "loss": 0.0743,
      "step": 1080
    },
    {
      "epoch": 1.9063867016622922,
      "grad_norm": 0.25442230701446533,
      "learning_rate": 3.546142931204062e-05,
      "loss": 0.0735,
      "step": 1090
    },
    {
      "epoch": 1.9238845144356955,
      "grad_norm": 0.25998958945274353,
      "learning_rate": 3.449110807600182e-05,
      "loss": 0.0693,
      "step": 1100
    },
    {
      "epoch": 1.9413823272090989,
      "grad_norm": 0.26790985465049744,
      "learning_rate": 3.352720737084994e-05,
      "loss": 0.0716,
      "step": 1110
    },
    {
      "epoch": 1.9588801399825022,
      "grad_norm": 0.2054957002401352,
      "learning_rate": 3.257012624213126e-05,
      "loss": 0.073,
      "step": 1120
    },
    {
      "epoch": 1.9763779527559056,
      "grad_norm": 0.4390679597854614,
      "learning_rate": 3.162026091215347e-05,
      "loss": 0.0651,
      "step": 1130
    },
    {
      "epoch": 1.993875765529309,
      "grad_norm": 0.2131059765815735,
      "learning_rate": 3.067800461595355e-05,
      "loss": 0.0711,
      "step": 1140
    },
    {
      "epoch": 2.010498687664042,
      "grad_norm": 0.2149074673652649,
      "learning_rate": 2.9743747438502316e-05,
      "loss": 0.0712,
      "step": 1150
    },
    {
      "epoch": 2.027996500437445,
      "grad_norm": 0.29382169246673584,
      "learning_rate": 2.8817876153212958e-05,
      "loss": 0.0658,
      "step": 1160
    },
    {
      "epoch": 2.0454943132108485,
      "grad_norm": 0.20028123259544373,
      "learning_rate": 2.7900774061820613e-05,
      "loss": 0.0712,
      "step": 1170
    },
    {
      "epoch": 2.062992125984252,
      "grad_norm": 0.2501092255115509,
      "learning_rate": 2.6992820835699133e-05,
      "loss": 0.0699,
      "step": 1180
    },
    {
      "epoch": 2.080489938757655,
      "grad_norm": 0.21082265675067902,
      "learning_rate": 2.609439235868092e-05,
      "loss": 0.069,
      "step": 1190
    },
    {
      "epoch": 2.0979877515310585,
      "grad_norm": 0.2408638596534729,
      "learning_rate": 2.5205860571444563e-05,
      "loss": 0.0621,
      "step": 1200
    },
    {
      "epoch": 2.115485564304462,
      "grad_norm": 0.2946993410587311,
      "learning_rate": 2.4327593317535045e-05,
      "loss": 0.0667,
      "step": 1210
    },
    {
      "epoch": 2.1329833770778652,
      "grad_norm": 0.3420477509498596,
      "learning_rate": 2.3459954191080065e-05,
      "loss": 0.0664,
      "step": 1220
    },
    {
      "epoch": 2.1504811898512686,
      "grad_norm": 0.38461872935295105,
      "learning_rate": 2.2603302386265567e-05,
      "loss": 0.0676,
      "step": 1230
    },
    {
      "epoch": 2.167979002624672,
      "grad_norm": 0.257321298122406,
      "learning_rate": 2.175799254863294e-05,
      "loss": 0.0694,
      "step": 1240
    },
    {
      "epoch": 2.1854768153980753,
      "grad_norm": 0.3844687044620514,
      "learning_rate": 2.092437462825908e-05,
      "loss": 0.0694,
      "step": 1250
    },
    {
      "epoch": 2.2029746281714786,
      "grad_norm": 0.22922861576080322,
      "learning_rate": 2.010279373488053e-05,
      "loss": 0.068,
      "step": 1260
    },
    {
      "epoch": 2.220472440944882,
      "grad_norm": 0.23497329652309418,
      "learning_rate": 1.9293589995021337e-05,
      "loss": 0.0705,
      "step": 1270
    },
    {
      "epoch": 2.2379702537182853,
      "grad_norm": 0.2932192385196686,
      "learning_rate": 1.8497098411183973e-05,
      "loss": 0.0669,
      "step": 1280
    },
    {
      "epoch": 2.2554680664916886,
      "grad_norm": 0.2852768301963806,
      "learning_rate": 1.771364872316163e-05,
      "loss": 0.0686,
      "step": 1290
    },
    {
      "epoch": 2.272965879265092,
      "grad_norm": 0.2550954520702362,
      "learning_rate": 1.6943565271529045e-05,
      "loss": 0.0667,
      "step": 1300
    },
    {
      "epoch": 2.2904636920384953,
      "grad_norm": 0.34992000460624695,
      "learning_rate": 1.6187166863368713e-05,
      "loss": 0.0695,
      "step": 1310
    },
    {
      "epoch": 2.3079615048118987,
      "grad_norm": 0.3591824173927307,
      "learning_rate": 1.544476664028779e-05,
      "loss": 0.0693,
      "step": 1320
    },
    {
      "epoch": 2.325459317585302,
      "grad_norm": 0.2637813985347748,
      "learning_rate": 1.4716671948780513e-05,
      "loss": 0.0648,
      "step": 1330
    },
    {
      "epoch": 2.3429571303587053,
      "grad_norm": 0.22962366044521332,
      "learning_rate": 1.40031842129898e-05,
      "loss": 0.066,
      "step": 1340
    },
    {
      "epoch": 2.3604549431321082,
      "grad_norm": 0.2959223687648773,
      "learning_rate": 1.33045988099205e-05,
      "loss": 0.0631,
      "step": 1350
    },
    {
      "epoch": 2.377952755905512,
      "grad_norm": 0.20330236852169037,
      "learning_rate": 1.262120494715624e-05,
      "loss": 0.0675,
      "step": 1360
    },
    {
      "epoch": 2.395450568678915,
      "grad_norm": 0.27373817563056946,
      "learning_rate": 1.195328554313016e-05,
      "loss": 0.0663,
      "step": 1370
    },
    {
      "epoch": 2.4129483814523183,
      "grad_norm": 0.3489779531955719,
      "learning_rate": 1.130111710999961e-05,
      "loss": 0.0667,
      "step": 1380
    },
    {
      "epoch": 2.4304461942257216,
      "grad_norm": 0.30409348011016846,
      "learning_rate": 1.0664969639172672e-05,
      "loss": 0.0622,
      "step": 1390
    },
    {
      "epoch": 2.447944006999125,
      "grad_norm": 0.3190676271915436,
      "learning_rate": 1.0045106489534389e-05,
      "loss": 0.0684,
      "step": 1400
    },
    {
      "epoch": 2.4654418197725283,
      "grad_norm": 0.23547764122486115,
      "learning_rate": 9.441784278418686e-06,
      "loss": 0.0671,
      "step": 1410
    },
    {
      "epoch": 2.4829396325459316,
      "grad_norm": 0.3248685300350189,
      "learning_rate": 8.85525277537132e-06,
      "loss": 0.0673,
      "step": 1420
    },
    {
      "epoch": 2.500437445319335,
      "grad_norm": 0.3447372019290924,
      "learning_rate": 8.285754798747736e-06,
      "loss": 0.0634,
      "step": 1430
    },
    {
      "epoch": 2.5179352580927383,
      "grad_norm": 0.29736822843551636,
      "learning_rate": 7.733526115188567e-06,
      "loss": 0.0664,
      "step": 1440
    },
    {
      "epoch": 2.5354330708661417,
      "grad_norm": 0.2758426368236542,
      "learning_rate": 7.198795342014575e-06,
      "loss": 0.0684,
      "step": 1450
    },
    {
      "epoch": 2.552930883639545,
      "grad_norm": 0.24664311110973358,
      "learning_rate": 6.681783852581252e-06,
      "loss": 0.0644,
      "step": 1460
    },
    {
      "epoch": 2.5704286964129484,
      "grad_norm": 0.25151732563972473,
      "learning_rate": 6.182705684632429e-06,
      "loss": 0.0651,
      "step": 1470
    },
    {
      "epoch": 2.5879265091863517,
      "grad_norm": 0.3254878520965576,
      "learning_rate": 5.701767451690726e-06,
      "loss": 0.0641,
      "step": 1480
    },
    {
      "epoch": 2.605424321959755,
      "grad_norm": 0.2798231244087219,
      "learning_rate": 5.239168257521549e-06,
      "loss": 0.064,
      "step": 1490
    },
    {
      "epoch": 2.6229221347331584,
      "grad_norm": 0.29080405831336975,
      "learning_rate": 4.7950996137060666e-06,
      "loss": 0.0642,
      "step": 1500
    },
    {
      "epoch": 2.6404199475065617,
      "grad_norm": 0.3001261055469513,
      "learning_rate": 4.369745360357258e-06,
      "loss": 0.065,
      "step": 1510
    },
    {
      "epoch": 2.657917760279965,
      "grad_norm": 0.33026012778282166,
      "learning_rate": 3.963281590011892e-06,
      "loss": 0.0705,
      "step": 1520
    },
    {
      "epoch": 2.6754155730533684,
      "grad_norm": 0.24986456334590912,
      "learning_rate": 3.575876574729947e-06,
      "loss": 0.0644,
      "step": 1530
    },
    {
      "epoch": 2.6929133858267718,
      "grad_norm": 0.2775067687034607,
      "learning_rate": 3.207690696431581e-06,
      "loss": 0.064,
      "step": 1540
    },
    {
      "epoch": 2.710411198600175,
      "grad_norm": 0.2663014233112335,
      "learning_rate": 2.858876380500608e-06,
      "loss": 0.0649,
      "step": 1550
    },
    {
      "epoch": 2.7279090113735784,
      "grad_norm": 0.30557385087013245,
      "learning_rate": 2.5295780326818063e-06,
      "loss": 0.0668,
      "step": 1560
    },
    {
      "epoch": 2.745406824146982,
      "grad_norm": 0.25767281651496887,
      "learning_rate": 2.2199319792983896e-06,
      "loss": 0.0655,
      "step": 1570
    },
    {
      "epoch": 2.7629046369203847,
      "grad_norm": 0.24847812950611115,
      "learning_rate": 1.9300664108142298e-06,
      "loss": 0.0677,
      "step": 1580
    },
    {
      "epoch": 2.7804024496937885,
      "grad_norm": 0.258283793926239,
      "learning_rate": 1.6601013287642297e-06,
      "loss": 0.0631,
      "step": 1590
    },
    {
      "epoch": 2.7979002624671914,
      "grad_norm": 0.3107544779777527,
      "learning_rate": 1.410148496074859e-06,
      "loss": 0.064,
      "step": 1600
    },
    {
      "epoch": 2.815398075240595,
      "grad_norm": 0.30439576506614685,
      "learning_rate": 1.1803113907953855e-06,
      "loss": 0.0655,
      "step": 1610
    },
    {
      "epoch": 2.832895888013998,
      "grad_norm": 0.2965574264526367,
      "learning_rate": 9.706851632589498e-07,
      "loss": 0.0651,
      "step": 1620
    },
    {
      "epoch": 2.850393700787402,
      "grad_norm": 0.29829102754592896,
      "learning_rate": 7.813565966912905e-07,
      "loss": 0.0712,
      "step": 1630
    },
    {
      "epoch": 2.8678915135608047,
      "grad_norm": 0.3737465739250183,
      "learning_rate": 6.124040712832846e-07,
      "loss": 0.0685,
      "step": 1640
    },
    {
      "epoch": 2.885389326334208,
      "grad_norm": 0.2790295481681824,
      "learning_rate": 4.638975317423522e-07,
      "loss": 0.0666,
      "step": 1650
    },
    {
      "epoch": 2.9028871391076114,
      "grad_norm": 0.32066580653190613,
      "learning_rate": 3.358984583359703e-07,
      "loss": 0.064,
      "step": 1660
    },
    {
      "epoch": 2.9203849518810148,
      "grad_norm": 0.3083692789077759,
      "learning_rate": 2.2845984143949895e-07,
      "loss": 0.0659,
      "step": 1670
    },
    {
      "epoch": 2.937882764654418,
      "grad_norm": 0.22819280624389648,
      "learning_rate": 1.4162615959863457e-07,
      "loss": 0.0632,
      "step": 1680
    },
    {
      "epoch": 2.9553805774278215,
      "grad_norm": 0.4019409716129303,
      "learning_rate": 7.543336111575094e-08,
      "loss": 0.066,
      "step": 1690
    },
    {
      "epoch": 2.972878390201225,
      "grad_norm": 0.2499573975801468,
      "learning_rate": 2.990884916763137e-08,
      "loss": 0.0705,
      "step": 1700
    },
    {
      "epoch": 2.990376202974628,
      "grad_norm": 0.3189394176006317,
      "learning_rate": 5.071470460832339e-09,
      "loss": 0.0669,
      "step": 1710
    },
    {
      "epoch": 3.0,
      "step": 1716,
      "total_flos": 9.247335010433434e+16,
      "train_loss": 0.08458727698920768,
      "train_runtime": 6992.2554,
      "train_samples_per_second": 7.846,
      "train_steps_per_second": 0.245
    }
  ],
  "logging_steps": 10,
  "max_steps": 1716,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.247335010433434e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
