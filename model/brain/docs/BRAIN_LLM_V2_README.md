# Brain LLM V2 è®­ç»ƒæŒ‡å—

> **æ–°æ¶æ„**: local_chat å§‹ç»ˆè°ƒç”¨ + å¤šå·¥å…·å¹¶è¡Œå†³ç­–

## ğŸ¯ æ¶æ„å˜åŒ–

### V1 (æ—§æ¶æ„)
- å•å·¥å…·è·¯ç”±ï¼šæ¯æ¬¡åªé€‰æ‹©ä¸€ä¸ªå·¥å…·
- é—®é¢˜ï¼šç›´æ¥è°ƒç”¨ `psychological_assessment` é€ æˆå¯¹è¯å‰²è£‚æ„Ÿ

### V2 (æ–°æ¶æ„) âœ…
- `local_chat` **å¿…é¡»è°ƒç”¨**ï¼šæ¯æ¬¡éƒ½ç”Ÿæˆå¯¹è¯å“åº”
- å¤šå·¥å…·å¹¶è¡Œï¼šæ ¹æ®éœ€è¦åŒæ—¶è°ƒç”¨å…¶ä»–å·¥å…·
- ä¼˜åŠ¿ï¼šä¿è¯å¯¹è¯è¿è´¯æ€§ï¼ŒåŒæ—¶è¿›è¡Œä¸“ä¸šè¯„ä¼°

## ğŸ“Š è®­ç»ƒæ•°æ®

### æ•°æ®åˆ†å¸ƒ
- **æ€»è®¡**: 250 æ¡æ ·æœ¬
- **ä»… local_chat**: 201 æ¡ (80.4%)
- **local_chat + assessment**: 39 æ¡ (15.6%)
- **local_chat + memory_query**: 10 æ¡ (4.0%)

### æ•°æ®æ¥æº
1. **æ ¸å¿ƒæ ·æœ¬** (50æ¡): æ‰‹å·¥è®¾è®¡çš„é«˜è´¨é‡æ ·æœ¬ï¼Œè¦†ç›–æ‰€æœ‰åœºæ™¯
2. **å¿ƒç†å’¨è¯¢æ•°æ®** (80æ¡): ä»çœŸå®å¿ƒç†å’¨è¯¢å¯¹è¯ä¸­æå–
3. **Alpacaä¸­æ–‡æ•°æ®** (120æ¡): é€šç”¨å¯¹è¯åœºæ™¯

### è¾“å‡ºæ ¼å¼

```json
{
  "tools": [
    {"name": "local_chat", "parameters": {"user_input": "ç”¨æˆ·è¾“å…¥"}},
    {"name": "psychological_assessment", "parameters": {"trigger_reason": "è§¦å‘åŸå› "}}
  ]
}
```

## ğŸš€ è®­ç»ƒæµç¨‹

### 1. å¼€å§‹è®­ç»ƒ

```bash
cd /home/zanewang/projects/fine-tuning
./train_brain.sh
```

**é¢„è®¡æ—¶é—´**: 2-3å°æ—¶ï¼ˆå–å†³äºGPUï¼‰
**æ˜¾å­˜éœ€æ±‚**: çº¦ 6-8GB

### 2. è®­ç»ƒé…ç½®

- **åŸºåº§æ¨¡å‹**: Qwen2.5-0.5B-Instruct
- **å¾®è°ƒæ–¹æ³•**: LoRA (rank=16, alpha=32)
- **å­¦ä¹ ç‡**: 3e-4
- **è®­ç»ƒè½®æ•°**: 5 epochs
- **æ‰¹æ¬¡å¤§å°**: 4 (æ¢¯åº¦ç´¯ç§¯ x4)
- **éªŒè¯é›†**: 10%

### 3. æµ‹è¯•æ¨¡å‹

```bash
python test_brain_model.py
```

**æµ‹è¯•å†…å®¹**:
- 14ä¸ªæµ‹è¯•ç”¨ä¾‹
- è¦†ç›–ä¸‰ç§åœºæ™¯ï¼ˆçº¯èŠå¤©ã€è¯„ä¼°ã€å†å²æŸ¥è¯¢ï¼‰
- è¾“å‡ºå‡†ç¡®ç‡ç»Ÿè®¡

### 4. åˆå¹¶ LoRA æƒé‡

```bash
python merge_brain_lora.py
```

**è¾“å‡º**: `output/qwen2.5-0.5b-brain-merged/`

### 5. è½¬æ¢ä¸º GGUF

```bash
./convert_brain_to_gguf.sh
```

**è¾“å‡ºæ–‡ä»¶**:
- `brain-fp16.gguf` (çº¦ 1GB)
- `brain-q4_k_m.gguf` (çº¦ 350MB, **æ¨èç”¨äº Android**)
- `brain-q8_0.gguf` (çº¦ 530MB, é«˜è´¨é‡)

## ğŸ“± Android é›†æˆ

### æ ¸å¿ƒé€»è¾‘

```java
// 1. Brain LLM å†³ç­–
String brainOutput = brainModel.generate(userInput);
JSONObject decision = parseDecision(brainOutput);
JSONArray tools = decision.getJSONArray("tools");

// 2. æ‰§è¡Œæ‰€æœ‰å·¥å…·
String chatResponse = null;
AssessmentResult assessmentResult = null;
List<Memory> memories = null;

for (int i = 0; i < tools.length(); i++) {
    JSONObject tool = tools.getJSONObject(i);
    String toolName = tool.getString("name");
    JSONObject params = tool.getJSONObject("parameters");
    
    switch (toolName) {
        case "local_chat":
            // è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå¯¹è¯
            chatResponse = chatModel.generate(params.getString("user_input"));
            break;
        case "psychological_assessment":
            // è°ƒç”¨è¯„ä¼°å·¥å…·
            assessmentResult = assessmentTool.assess(params.getString("trigger_reason"));
            break;
        case "memory_query":
            // æŸ¥è¯¢å†å²è®°å½•
            memories = memoryDB.query(params.getString("query"));
            break;
    }
}

// 3. æ•´åˆç»“æœ
String finalResponse = integrateResults(chatResponse, assessmentResult, memories);
return finalResponse;
```

### ç»“æœæ•´åˆç­–ç•¥

1. **ä»… local_chat**: ç›´æ¥è¿”å›å¯¹è¯å“åº”
2. **local_chat + assessment**: 
   - å…ˆå±•ç¤ºèŠå¤©å†…å®¹ï¼ˆè¡¨ç¤ºå…³å¿ƒï¼‰
   - ç„¶åå±•ç¤ºè¯„ä¼°ç»“æœå’Œå»ºè®®
3. **local_chat + memory**: 
   - å°†å†å²è®°å½•æ³¨å…¥åˆ°èŠå¤©ä¸Šä¸‹æ–‡
   - è¿”å›å¸¦æœ‰å†å²ä¿¡æ¯çš„å›å¤

## ğŸ” è¯„ä¼°æŒ‡æ ‡

### è®­ç»ƒæŒ‡æ ‡
- **Train Loss**: åº”é™è‡³ 0.05-0.1
- **Eval Loss**: åº”æ¥è¿‘ train loss
- **æ ¼å¼æ­£ç¡®ç‡**: åº” >95%

### æµ‹è¯•æŒ‡æ ‡
- **å·¥å…·é€‰æ‹©å‡†ç¡®ç‡**: >90%
- **JSON è§£ææˆåŠŸç‡**: 100%
- **æ¨ç†é€Ÿåº¦**: <100ms (Q4é‡åŒ–)

## ğŸ’¡ è°ƒä¼˜å»ºè®®

### å¦‚æœè®­ç»ƒlossä¸é™
- å¢åŠ  learning_rate åˆ° 5e-4
- å¢åŠ  epoch åˆ° 8-10
- æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®

### å¦‚æœæµ‹è¯•å‡†ç¡®ç‡ä½
- å¢åŠ è®­ç»ƒæ•°æ®ï¼ˆç‰¹åˆ«æ˜¯è¾¹ç•Œcaseï¼‰
- è°ƒæ•´ lora_rank åˆ° 32
- ä½¿ç”¨å…¨é‡å¾®è°ƒè€Œé LoRA

### å¦‚æœæ¨ç†é€Ÿåº¦æ…¢
- ä½¿ç”¨ Q4_K_M é‡åŒ–
- å‡å°‘ max_new_tokens åˆ° 100
- è€ƒè™‘ä½¿ç”¨ Qwen2-0.5Bï¼ˆæ›´å°ï¼‰

## ğŸ“¦ æ–‡ä»¶ç»“æ„

```
fine-tuning/
â”œâ”€â”€ brain_train_config.yaml           # è®­ç»ƒé…ç½®
â”œâ”€â”€ train_brain.sh                    # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_brain_model.py               # æµ‹è¯•è„šæœ¬
â”œâ”€â”€ merge_brain_lora.py               # åˆå¹¶è„šæœ¬
â”œâ”€â”€ convert_brain_to_gguf.sh          # é‡åŒ–è„šæœ¬
â”œâ”€â”€ rebuild_brain_data_v2.py          # æ•°æ®ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ LLaMA-Factory/
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ brain_training_data_v2.json   # è®­ç»ƒæ•°æ®
â”‚       â””â”€â”€ dataset_info.json             # æ•°æ®é›†æ³¨å†Œ
â”œâ”€â”€ saves/
â”‚   â””â”€â”€ Qwen2.5-0.5B-Brain/
â”‚       â””â”€â”€ lora/sft/                 # LoRA æƒé‡
â””â”€â”€ output/
    â”œâ”€â”€ qwen2.5-0.5b-brain-merged/    # åˆå¹¶åçš„æ¨¡å‹
    â””â”€â”€ brain-gguf/                   # GGUF æ–‡ä»¶
```

## ğŸ“ æœ€ä½³å®è·µ

1. **æ•°æ®è´¨é‡ > æ•°é‡**: 250æ¡é«˜è´¨é‡æ•°æ®è¶³å¤Ÿ
2. **æ ¼å¼ä¸€è‡´æ€§**: ç¡®ä¿è®­ç»ƒå’Œæ¨ç†æ—¶ system prompt ä¸€è‡´
3. **æ¸©åº¦æ§åˆ¶**: æ¨ç†æ—¶ä½¿ç”¨ä½æ¸©åº¦(0.1-0.3)ä¿è¯æ ¼å¼ç¨³å®š
4. **é”™è¯¯å¤„ç†**: å§‹ç»ˆéªŒè¯ JSON è§£æç»“æœ
5. **ä¼˜é›…é™çº§**: JSON è§£æå¤±è´¥æ—¶ï¼Œé»˜è®¤è°ƒç”¨ local_chat

## ğŸ“ æ•…éšœæ’é™¤

### Q: è®­ç»ƒæ—¶æ˜¾å­˜ä¸è¶³
A: å‡å° `per_device_train_batch_size` åˆ° 2ï¼Œå¢åŠ  `gradient_accumulation_steps` åˆ° 8

### Q: æ¨¡å‹æ€»æ˜¯è¾“å‡ºæ ¼å¼é”™è¯¯
A: å¢åŠ è®­ç»ƒè½®æ•°ï¼Œæˆ–åœ¨æ•°æ®ä¸­æ·»åŠ æ›´å¤šæ ¼å¼ç¤ºä¾‹

### Q: psychological_assessment è§¦å‘è¿‡äºé¢‘ç¹/ä¸è¶³
A: è°ƒæ•´è®­ç»ƒæ•°æ®ä¸­è¯„ä¼°æ ·æœ¬çš„æ¯”ä¾‹ï¼Œæˆ–ä¿®æ”¹ system prompt ä¸­çš„è§¦å‘æ¡ä»¶æè¿°

### Q: Android ä¸Šæ¨ç†å¤ªæ…¢
A: ä½¿ç”¨ Q4_K_M é‡åŒ–ï¼Œæˆ–è€ƒè™‘ä½¿ç”¨æ›´å°çš„åŸºåº§æ¨¡å‹ï¼ˆå¦‚ Qwen2-0.25Bï¼‰

---

**ç‰ˆæœ¬**: V2.0  
**æ›´æ–°æ—¥æœŸ**: 2025-12-02  
**ä½œè€…**: AI Assistant

