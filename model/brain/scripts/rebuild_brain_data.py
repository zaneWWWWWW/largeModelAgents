#!/usr/bin/env python3
"""
é‡æ„ Brain LLM è®­ç»ƒæ•°æ®
æ–°æ¶æ„ï¼šlocal_chat å§‹ç»ˆè°ƒç”¨ + å¯é€‰å…¶ä»–å·¥å…·
"""

import json
import random
from typing import List, Dict

# æ–°çš„ System Prompt
NEW_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å¿ƒç†å’¨è¯¢åŠ©æ‰‹çš„å†³ç­–å¤§è„‘(Brain LLM)ã€‚ä½ çš„èŒè´£æ˜¯æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œåˆ¤æ–­éœ€è¦è°ƒç”¨å“ªäº›å·¥å…·ã€‚

ğŸ”§ å¯ç”¨å·¥å…·ï¼š

1. local_chatï¼ˆå¿…é¡»è°ƒç”¨ï¼‰
   - æè¿°ï¼šç”Ÿæˆå¯¹è¯å›å¤ï¼Œæä¾›æƒ…æ„Ÿæ”¯æŒå’Œå»ºè®®
   - å‚æ•°ï¼š{"user_input": "ç”¨æˆ·çš„åŸå§‹è¾“å…¥"}
   - è¯´æ˜ï¼šæ¯æ¬¡éƒ½å¿…é¡»è°ƒç”¨ï¼Œæ˜¯ä¸ç”¨æˆ·äº¤äº’çš„ä¸»è¦æ–¹å¼

2. psychological_assessmentï¼ˆæŒ‰éœ€è°ƒç”¨ï¼‰
   - æè¿°ï¼šå½“ç”¨æˆ·è¡¨è¾¾ä¸¥é‡å¿ƒç†å›°æ‰°æ—¶ï¼Œè¿›è¡Œä¸“ä¸šè¯„ä¼°
   - å‚æ•°ï¼š{"trigger_reason": "è§¦å‘è¯„ä¼°çš„å…·ä½“åŸå› "}
   - è§¦å‘æ¡ä»¶ï¼šç„¦è™‘ã€æŠ‘éƒã€å¤±çœ ï¼ˆæŒç»­æ€§ï¼‰ã€è‡ªæ€/è‡ªä¼¤å€¾å‘ã€å¼ºè¿«è¡Œä¸ºç­‰

3. memory_queryï¼ˆæŒ‰éœ€è°ƒç”¨ï¼‰
   - æè¿°ï¼šæŸ¥è¯¢å†å²å¯¹è¯è®°å½•
   - å‚æ•°ï¼š{"query": "æŸ¥è¯¢å…³é”®è¯"}
   - è§¦å‘æ¡ä»¶ï¼šç”¨æˆ·æ˜ç¡®è¯¢é—®å†å²å¯¹è¯å†…å®¹

ğŸ“‹ è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
```json
{
  "tools": [
    {"name": "local_chat", "parameters": {"user_input": "..."}},
    {"name": "psychological_assessment", "parameters": {"trigger_reason": "..."}}
  ]
}
```

âš ï¸ é‡è¦è§„åˆ™ï¼š
1. tools æ•°ç»„ä¸­å¿…é¡»åŒ…å« local_chat
2. æ ¹æ®éœ€è¦æ·»åŠ å…¶ä»–å·¥å…·ï¼ˆ0-2ä¸ªï¼‰
3. åªè¾“å‡º JSONï¼Œä¸è¦é¢å¤–è§£é‡Š"""


def convert_single_tool_to_multi(old_sample: Dict) -> Dict:
    """å°†å•å·¥å…·å†³ç­–è½¬æ¢ä¸ºå¤šå·¥å…·å†³ç­–"""
    conversations = old_sample.get("conversations", [])
    new_conversations = []
    
    for conv in conversations:
        if conv["from"] == "system":
            # æ›¿æ¢ä¸ºæ–°çš„ system prompt
            new_conversations.append({
                "from": "system",
                "value": NEW_SYSTEM_PROMPT
            })
        elif conv["from"] == "user":
            new_conversations.append(conv)
        elif conv["from"] == "assistant":
            # è§£æåŸå§‹å·¥å…·è°ƒç”¨
            old_value = conv["value"]
            
            # æå– JSON
            try:
                import re
                json_match = re.search(r'\{.*?\}', old_value, re.DOTALL)
                if json_match:
                    old_tool_call = json.loads(json_match.group(0))
                    tool_name = old_tool_call.get("tool", "")
                    parameters = old_tool_call.get("parameters", {})
                    
                    # æ„å»ºæ–°çš„å¤šå·¥å…·è°ƒç”¨
                    tools = []
                    
                    # 1. å¿…é¡»åŒ…å« local_chat
                    if tool_name == "local_chat":
                        tools.append({
                            "name": "local_chat",
                            "parameters": parameters
                        })
                    elif tool_name == "memory_query":
                        # memory_query åœºæ™¯ï¼šå…ˆæŸ¥è¯¢ï¼Œå†èŠå¤©
                        tools.append({
                            "name": "local_chat",
                            "parameters": {"user_input": parameters.get("query", "")}
                        })
                        tools.append({
                            "name": "memory_query",
                            "parameters": parameters
                        })
                    elif tool_name == "psychological_assessment":
                        # è¯„ä¼°åœºæ™¯ï¼šå…ˆèŠå¤©è¡¨ç¤ºå…³å¿ƒï¼Œå†è¯„ä¼°
                        user_input = ""
                        for c in new_conversations:
                            if c["from"] == "user":
                                user_input = c["value"]
                        
                        tools.append({
                            "name": "local_chat",
                            "parameters": {"user_input": user_input}
                        })
                        tools.append({
                            "name": "psychological_assessment",
                            "parameters": parameters
                        })
                    
                    # ç”Ÿæˆæ–°çš„è¾“å‡º
                    new_output = {
                        "tools": tools
                    }
                    
                    new_conversations.append({
                        "from": "assistant",
                        "value": f"```json\n{json.dumps(new_output, ensure_ascii=False, indent=2)}\n```"
                    })
                else:
                    # æ— æ³•è§£æï¼Œä¿ç•™åŸæ ·
                    new_conversations.append(conv)
            except Exception as e:
                print(f"è½¬æ¢å¤±è´¥: {e}, ä¿ç•™åŸæ ·")
                new_conversations.append(conv)
        else:
            # tool æˆ–å…¶ä»–è§’è‰²
            new_conversations.append(conv)
    
    return {"conversations": new_conversations}


def create_sample_from_psychology_data(psych_data: Dict) -> Dict:
    """ä»å¿ƒç†å’¨è¯¢æ•°æ®åˆ›å»ºè®­ç»ƒæ ·æœ¬"""
    user_input = psych_data.get("input", "").strip()
    if not user_input or len(user_input) < 10:
        return None
    
    # æå–ç¬¬ä¸€å¥å­¦ç”Ÿçš„è¯ä½œä¸ºç®€çŸ­è¾“å…¥
    lines = user_input.split('\n')
    student_lines = [l.replace("å­¦ç”Ÿ: ", "").strip() for l in lines if l.startswith("å­¦ç”Ÿ:")]
    
    if not student_lines:
        return None
    
    first_input = student_lines[0]
    
    # åˆ¤æ–­æ˜¯å¦éœ€è¦è¯„ä¼°
    assessment_keywords = [
        "è‡ªæ€", "æ­»", "æ´»ç€æ²¡æ„æ€", "ç—›è‹¦", "ç„¦è™‘", "æŠ‘éƒ", "å¤±çœ ", 
        "ç¡ä¸ç€", "å‹åŠ›å¤§", "å´©æºƒ", "ç»æœ›", "å®³æ€•", "ææƒ§", "å¿ƒæ…Œ"
    ]
    
    needs_assessment = any(kw in first_input for kw in assessment_keywords)
    
    tools = [
        {
            "name": "local_chat",
            "parameters": {"user_input": first_input}
        }
    ]
    
    if needs_assessment:
        # æå–è§¦å‘åŸå› 
        trigger = "ç”¨æˆ·è¡¨è¾¾å¿ƒç†å›°æ‰°"
        if "è‡ªæ€" in first_input or "æ­»" in first_input or "æ´»ç€æ²¡æ„æ€" in first_input:
            trigger = "ç”¨æˆ·è¡¨è¾¾è‡ªæ€æ„å¿µæˆ–ç”Ÿæ´»æ— æ„ä¹‰æ„Ÿ"
        elif "ç„¦è™‘" in first_input or "å¿ƒæ…Œ" in first_input:
            trigger = "ç”¨æˆ·è¡¨è¾¾ç„¦è™‘ç—‡çŠ¶"
        elif "å¤±çœ " in first_input or "ç¡ä¸ç€" in first_input:
            trigger = "ç”¨æˆ·è¡¨è¾¾ä¸¥é‡ç¡çœ é—®é¢˜"
        elif "æŠ‘éƒ" in first_input or "ä½è½" in first_input:
            trigger = "ç”¨æˆ·è¡¨è¾¾æŠ‘éƒæƒ…ç»ª"
        
        tools.append({
            "name": "psychological_assessment",
            "parameters": {"trigger_reason": trigger}
        })
    
    output = {"tools": tools}
    
    return {
        "conversations": [
            {"from": "system", "value": NEW_SYSTEM_PROMPT},
            {"from": "user", "value": first_input},
            {"from": "assistant", "value": f"```json\n{json.dumps(output, ensure_ascii=False, indent=2)}\n```"}
        ]
    }


def create_sample_from_alpaca(alpaca_data: Dict) -> Dict:
    """ä» Alpaca æ•°æ®åˆ›å»ºè®­ç»ƒæ ·æœ¬ï¼ˆä»… local_chatï¼‰"""
    instruction = alpaca_data.get("instruction", "").strip()
    input_text = alpaca_data.get("input", "").strip()
    
    if not instruction:
        return None
    
    user_input = f"{instruction}\n{input_text}".strip() if input_text else instruction
    
    # é™åˆ¶é•¿åº¦
    if len(user_input) > 100:
        user_input = user_input[:100]
    
    tools = [
        {
            "name": "local_chat",
            "parameters": {"user_input": user_input}
        }
    ]
    
    output = {"tools": tools}
    
    return {
        "conversations": [
            {"from": "system", "value": NEW_SYSTEM_PROMPT},
            {"from": "user", "value": user_input},
            {"from": "assistant", "value": f"```json\n{json.dumps(output, ensure_ascii=False, indent=2)}\n```"}
        ]
    }


def main():
    print("=" * 60)
    print("ğŸ”„ é‡æ„ Brain LLM è®­ç»ƒæ•°æ®")
    print("=" * 60)
    
    # 1. è½¬æ¢ç°æœ‰ 52 æ¡æ ·æœ¬
    print("\n1ï¸âƒ£ è½¬æ¢ç°æœ‰ 52 æ¡æ ·æœ¬...")
    with open("data/brain_training_data.json", "r", encoding="utf-8") as f:
        old_samples = json.load(f)
    
    new_samples = []
    for sample in old_samples:
        converted = convert_single_tool_to_multi(sample)
        new_samples.append(converted)
    
    print(f"   âœ… è½¬æ¢å®Œæˆ: {len(new_samples)} æ¡")
    
    # 2. ä»å¿ƒç†å’¨è¯¢æ•°æ®æå–
    print("\n2ï¸âƒ£ ä»å¿ƒç†å’¨è¯¢æ•°æ®æå–...")
    with open("LLaMA-Factory/data/psychology_pending.json", "r", encoding="utf-8") as f:
        psych_data = json.load(f)
    
    psych_samples = []
    for item in psych_data:
        sample = create_sample_from_psychology_data(item)
        if sample:
            psych_samples.append(sample)
    
    print(f"   âœ… æå–: {len(psych_samples)} æ¡")
    
    # 3. ä» Alpaca æ•°æ®æå–
    print("\n3ï¸âƒ£ ä» Alpaca æ•°æ®æå–...")
    with open("LLaMA-Factory/data/alpaca_zh_demo.json", "r", encoding="utf-8") as f:
        alpaca_data = json.load(f)
    
    # éšæœºæŠ½æ ·
    sampled_alpaca = random.sample(alpaca_data, min(150, len(alpaca_data)))
    
    alpaca_samples = []
    for item in sampled_alpaca:
        sample = create_sample_from_alpaca(item)
        if sample:
            alpaca_samples.append(sample)
    
    print(f"   âœ… æå–: {len(alpaca_samples)} æ¡")
    
    # 4. åˆå¹¶å¹¶é™åˆ¶åˆ° 250 æ¡å·¦å³
    print("\n4ï¸âƒ£ åˆå¹¶æ•°æ®...")
    all_samples = new_samples + psych_samples[:100] + alpaca_samples[:100]
    
    # æ‰“ä¹±é¡ºåº
    random.shuffle(all_samples)
    
    print(f"   æ€»è®¡: {len(all_samples)} æ¡")
    
    # 5. ç»Ÿè®¡
    local_only = 0
    with_assessment = 0
    with_memory = 0
    
    for sample in all_samples:
        for conv in sample["conversations"]:
            if conv["from"] == "assistant":
                if '"psychological_assessment"' in conv["value"]:
                    with_assessment += 1
                elif '"memory_query"' in conv["value"]:
                    with_memory += 1
                else:
                    local_only += 1
    
    print("\nğŸ“Š æ•°æ®åˆ†å¸ƒ:")
    print(f"   - ä»… local_chat: {local_only}")
    print(f"   - local_chat + assessment: {with_assessment}")
    print(f"   - local_chat + memory_query: {with_memory}")
    
    # 6. ä¿å­˜
    output_path = "LLaMA-Factory/data/brain_training_data_v2.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(all_samples, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ä¿å­˜åˆ°: {output_path}")
    print("=" * 60)


if __name__ == "__main__":
    main()

